set.seed(12345); n1=4; n2=5; n3=6
x1=cbind(rnorm(n1, mean=0, sd = 1),rnorm(n1, mean=0, sd = 1) )
x2=cbind(rnorm(n2, mean=4, sd = 1),rnorm(n2, mean=-4, sd = 1) )
x3=cbind(rnorm(n3, mean=5, sd = 1),rnorm(n3, mean=5, sd = 1) )
x1
x2
x = rbind(x1,x2,x3); colnames(x) = c("x", "y")
x
class=c(rep("black",n1),rep("blue",n2), rep("red",n3)); plot(x,col=class, pch=19, cex=1)
nc=3; windows()
nc=3; quartz()
x=scale(x,center=T,scale=T);
plot(x,col=class, type="n", pch=19, cex=1)
plot(x,col=class, type="n", pch=19, cex=1)
plot(x,col=class, pch=19, cex=1)
rownames(x)=1:(n1+n2+n3)
x
text(x,rownames(x),col=class)
x=scale(x,center=T,scale=T);
plot(x,col=class, type='n',pch=19, cex=1)
rownames(x)=1:(n1+n2+n3)
text(x,rownames(x),col=class)
d = dist(x,method='euclidian')
d
min(d)
?hclust
hc=hclust(x)
hc=hclust(x,method='ward.D2')
x
set.seed(12345); n1=4; n2=5; n3=6
x1=cbind(rnorm(n1, mean=0, sd = 1),rnorm(n1, mean=0, sd = 1) )
x2=cbind(rnorm(n2, mean=4, sd = 1),rnorm(n2, mean=-4, sd = 1) )
x3=cbind(rnorm(n3, mean=5, sd = 1),rnorm(n3, mean=5, sd = 1) )
x = rbind(x1,x2,x3); colnames(x) = c("x", "y")
x
x=scale(x,center=T,scale=T);
hc=hclust(x,method='ward.D2')
hc=hclust(d,method='ward.D2')
plot(hc)
clusters=cutree(hc,k=3)
rect.hclust(hc, k=3, border="red")
clusters
# -----------------
centers=aggregate(x, list(clusters), mean)
centers
mean
aggregate(x, list(clusters))
?aggregate
centers=centers[,-1]; k=nrow(centers)
centers
# -----------------
centers=aggregate(x, list(clusters), mean)
centers
centers=centers[,-1]; k=nrow(centers)
k
plot(x,col=clusters , pch=19, cex=0.75)
points(centers, col = 1:k, pch = 8, cex=2)
points(centers, col = 1:k, pch = 19, cex=1)
clusters
table(clusters)
clusters
centers
x
set.seed(12345); n1=4; n2=5; n3=6
x1=cbind(rnorm(n1, mean=0, sd = 1),rnorm(n1, mean=0, sd = 1) )
x2=cbind(rnorm(n2, mean=4, sd = 1),rnorm(n2, mean=-4, sd = 1) )
x3=cbind(rnorm(n3, mean=5, sd = 1),rnorm(n3, mean=5, sd = 1) )
x = rbind(x1,x2,x3); colnames(x) = c("x", "y")
x
cov(x,y)
cov(x)
mean(x)
colMeans(x)
x-colMeans(x)
colMeans(x)
?rep
rep(colMeans(x),15)
matrix(rep(colMeans(x),15),byrow = T,nrow=15)
x-matrix(rep(colMeans(x),15),byrow = T,nrow=15)
x_xbar = x-matrix(rep(colMeans(x),15),byrow = T,nrow=15)
x_xbar[1,]%*%t(x_xbar[1,])
sum = matrix(c(0,0,0,0),byrow=T,nrow=2)
for (i in 1:15){
sum = sum + x_xbar[i,]%*%t(x_xbar[i,])
}
sum
sum*(1/15)
cov(x)
sum*(1/14)
clusters
R2=function(x,clusters,k=3){
n=nrow(x); tss=var(x); tss=(n-1)*sum(diag(tss));
wss=0
for(j in 1:k){
cj=x[clusters==j,]; nj=nrow(cj); vj=var(cj); wssj=0
if(is.matrix(cj)) wssj=(nj-1)*sum(diag(vj)); wss=wss+wssj
}
}
R2(x,clusters,k=3)
R2=function(x,clusters,k=3){
n=nrow(x); tss=var(x); tss=(n-1)*sum(diag(tss));
wss=0
for(j in 1:k){
cj=x[clusters==j,]; nj=nrow(cj); vj=var(cj); wssj=0
if(is.matrix(cj)) wssj=(nj-1)*sum(diag(vj)); wss=wss+wssj
}
r2=1-wss/tss; cat("R2 = ",r2,"\n") return(r2)
}
R2=function(x,clusters,k=3){
n=nrow(x); tss=var(x); tss=(n-1)*sum(diag(tss));
wss=0
for(j in 1:k){
cj=x[clusters==j,]; nj=nrow(cj); vj=var(cj); wssj=0
if(is.matrix(cj)) wssj=(nj-1)*sum(diag(vj)); wss=wss+wssj
}
r2=1-wss/tss; cat("R2 = ",r2,"\n")
return(r2)
}
R2(x,clusters,3)
R2(x,clusters,2)
R2(x,clusters,3)
# -------------- K-means
k=3; kmc = kmeans(x, k); clusters=kmc$cluster
clusters
plot(x, pch=19, col = kmc$cluster)
# -------------- K-means
k=4; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, pch=19, col = kmc$cluster)
points(kmc$centers, col = 1:k, pch = 8, cex=2)
kmc$centers
points(kmc$centers, col = 1:k, pch = 19, cex=1)
clusters; table(clusters)
kmc$centers
# Determining the number of clusters
x=scale(x, center=TRUE, scale=TRUE); # scale x wss = (nrow(x)-1)*sum(apply(x,2,var))
k=3; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, pch=19, col = kmc$cluster)
points(kmc$centers, col = 1:k, pch = 8, cex=2)
points(kmc$centers, col = 1:k, pch = 19, cex=1)
clusters; table(clusters)
kmc$centers
x
# Determining the number of clusters
x=scale(x, center=TRUE, scale=TRUE); # scale x wss = (nrow(x)-1)*sum(apply(x,2,var))
x
kmc$withinss
for (i in 2:10) {
wss[i] = sum(kmeans(x,centers=i)$withinss)}
kmc$tot.withinss
sum(kmc$withinss)
wss = c()
for (i in 2:10) {
wss[i] = sum(kmeans(x,centers=i)$withinss)}
plot(wss, type="b", pch=19, xlab="k",ylab="WSS", main="The L-Curve")
for (i in 2:10) {
wss[i] = kmeans(x,centers=i)$tot.withinss}
plot(wss, type="b", pch=19, xlab="k",ylab="WSS", main="The L-Curve")
for (i in 2:10) {
wss[i] = kmeans(x,centers=i)$tot.withinss}
plot(wss, type="b", pch=19, xlab="k",ylab="WSS", main="The L-Curve")
for (i in 2:10) {
wss[i] = kmeans(x,centers=i)$tot.withinss}
plot(wss, type="b", pch=19, xlab="k",ylab="WSS", main="The L-Curve")
install.packages("fpc"); require(fpc)
set.seed(54321)
face=rFace(500, p = 2, nrep.top = 2, smile.coef = 0.6, dMoNo = 2, dNoEy = 0)
class = as.integer(attr(face,"grouping"))
k=length(table(class))
x=face; plot(x,col=class,pch=19,cex=0.8)
# ------------- hclust
d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D")
k=6;
clusters=cutree(hc, k=k) # cut tree into k clusters
plot(x,col=clusters,pch=19,cex=0.8)
centers=aggregate(x, list(clusters), mean)
centers=centers[,-1]; k=nrow(centers)
points(centers, col = 1:k, pch = 8, cex=2)
points(centers, col = 1:k, pch = 19, cex=1)
set.seed(54321)
face=rFace(500, p = 2, nrep.top = 2, smile.coef = 0.6, dMoNo = 2, dNoEy = 0)
class = as.integer(attr(face,"grouping"))
k=length(table(class))
x=face; plot(x,col=class,pch=19,cex=0.8)
# ------------- hclust
d = dist(x, method = "euclidean")
d
hc = hclust(d, method="ward.D")
rect.hclust(hc, k=6, border="red")
plot(hc)
rect.hclust(hc, k=6, border="red")
clusters=cutree(hc, k=k) # cut tree into k clusters
plot(x,col=clusters,pch=19,cex=0.8)
centers=aggregate(x, list(clusters), mean)
centers=centers[,-1]; k=nrow(centers)
centers
k
points(centers, col = 1:k, pch = 8, cex=2)
points(centers, col = 1:k, pch = 19, cex=1)
# --------------- kmeans
k=6; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster)
points(kmc$centers, col = 1:k, pch = 19, cex=1)
clusters; table(clusters)
centers
r2=R2(x, clusters, k)
# ---------------- Cars Data
x=mtcars; d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D")
clusters=cutree(hc, k=3) # cut tree into k clusters
plot(hc)
rect.hclust(hc, k=3, border="red")
# ---------------- kmeans
k=3; kmc = kmeans(x, k);
k=2; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster)
points(kmc$centers, col = 1:k, pch = 8, cex=2)
points(kmc$centers, col = 1:k, pch = 19, cex=1)
clusters; table(clusters)
kmc$centers
r2=R2(x, clusters, k)
# ----------------- iris data
library(datasets)
x=iris; class=x[,5]; x=x[,-5]; pairs(x,col=class,pch=19)
d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D2")
plot(hc) # display dendrogram k=3
clusters=cutree(hc, k) # cut tree into k clusters rect.hclust(hc, k, border="red")
rect.hclust(hc,k=3)
table(clusters, class) # Confusion matrix
k=3
x=iris; class=x[,5]; x=x[,-5]; pairs(x,col=class,pch=19)
d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D2")
plot(hc) # display dendrogram k=3
clusters=cutree(hc, k) # cut tree into k clusters rect.hclust(hc, k, border="red")
rect.hclust(hc,k=3)
table(clusters, class) # Confusion matrix
x=iris; class=x[,5]; x=x[,-5]; pairs(x,col=class,pch=19)
k=3; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster)
points(kmc$centers, col = 1:k, pch = 8, cex=2)
points(kmc$centers, col = 1:k, pch = 19, cex=1)
clusters; table(clusters)
cat("Cluster Centers:\n"); kmc$centers
table(clusters, class) # Confusion matrix
x=iris; class=x[,5]; x=x[,-5]; pairs(x,col=class,pch=19)
k=3; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster)
points(kmc$centers, col = 1:k, pch = 8, cex=2)
points(kmc$centers, col = 1:k, pch = 19, cex=1)
clusters; table(clusters)
cat("Cluster Centers:\n"); kmc$centers
table(clusters, class) # Confusion matrix
library(datasets);
x=faithful; plot(x,pch=19); class=(x[,1]>3)+1; plot(x,col=class,pch=19)
d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D2")
windows(); plot(hc) # display dendrogram
k=2; clusters=cutree(hc, k) # cut tree into k clusters rect.hclust(hc, k, border="red")
table(clusters, class) # Confusion matrix
minWeightBipartiteMatching <- function(clusteringA, clusteringB) {
require(clue)
idsA <- unique(clusteringA)  # distinct cluster ids in a
idsB <- unique(clusteringB)  # distinct cluster ids in b
nA <- length(clusteringA)  # number of instances in a
nB <- length(clusteringB)  # number of instances in b
if (length(idsA) != length(idsB) || nA != nB) {
stop("number of clusters or number of instances do not match")
}
nC <- length(idsA)
tupel <- c(1:nA)
# computeing the distance matrix
assignmentMatrix <- matrix(rep(-1, nC * nC), nrow = nC)
for (i in 1:nC) {
tupelClusterI <- tupel[clusteringA == i]
solRowI <- sapply(1:nC, function(i, clusterIDsB, tupelA_I) {
nA_I <- length(tupelA_I)  # number of elements in cluster I
tupelB_I <- tupel[clusterIDsB == i]
nB_I <- length(tupelB_I)
nTupelIntersect <- length(intersect(tupelA_I, tupelB_I))
return((nA_I - nTupelIntersect) + (nB_I - nTupelIntersect))
}, clusteringB, tupelClusterI)
assignmentMatrix[i, ] <- solRowI
}
# optimization
result <- solve_LSAP(assignmentMatrix, maximum = FALSE)
attr(result, "assignmentMatrix") <- assignmentMatrix
return(result)
}
# ---------------------------------------------------
# Example: The Iris data
data(iris); x=as.matrix(iris[,-5]); class=iris[,5]
class=c(rep(1,50),rep(2,50), rep(3,50))
# Heirarchical Clustering
d=dist(x)
hc=hclust(d, method = "complete", members = NULL)
clusters=cutree(hc, k=3)
cm=table(clusters,class); print(cm); #  plot(x,pch=19,col=hd.clust)
cat(" Wrong error.rate =",1-sum(diag(cm))/sum(cm),"\n")
match.label=minWeightBipartiteMatching(clusters,class)
id=c(match.label); cm=cm[,id];  print(cm)
cat("Error Rate:",1-sum(diag(cm))/sum(cm),"\n")
24/150
x=faithful; plot(x,pch=19); class=(x[,1]>3)+1; plot(x,col=class,pch=19)
d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D2")
windows(); plot(hc) # display dendrogram
k=2; clusters=cutree(hc, k) # cut tree into k clusters rect.hclust(hc, k, border="red")
table(clusters, class) # Confusion matrix
match.label=minWeightBipartiteMatching(clusters,class)
id=c(match.label); cm=cm[,id];  print(cm)
cat("Error Rate:",1-sum(diag(cm))/sum(cm),"\n")
class
clusters
match.label=minWeightBipartiteMatching(clusters,class)
id=c(match.label); cm=cm[,id];  print(cm)
match,label
match.label
# -------------------- kmeans
k=2; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster,pch=19)
points(kmc$centers, col = 1:k, pch = 8, cex=3)
points(kmc$centers, col = 4:k, pch = 19, cex=2)
4:2
kmc$centers
clusters; table(clusters)
clusters; table(clusters)
table(clusters)
cat("Cluster Centers:\n"); kmc$centers
table(clusters, class) # Confusion matrix
minWeightBipartiteMatching(clusters,class)
match.label = minWeightBipartiteMatching(clusters,class)
id=c(match.label); cm=cm[,id];  print(cm)
cat("Error Rate:",1-sum(diag(cm))/sum(cm),"\n")
class
clusters
levels(cluster)
levels(clusters)
type(clusters)
typeof(clusters)
clusters = as.data.frame(clusters)
clusters
class
match.label = minWeightBipartiteMatching(clusters,class)
class = as.data.frame(class)
nrow(class)
match.label = minWeightBipartiteMatching(clusters,class)
k=2; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster,pch=19)
points(kmc$centers, col = 1:k, pch = 8, cex=3)
points(kmc$centers, col = 4:k, pch = 19, cex=2)
clusters
table(clusters)
cat("Cluster Centers:\n"); kmc$centers
table(clusters, class) # Confusion matrix
x=faithful; plot(x,pch=19); class=(x[,1]>3)+1; plot(x,col=class,pch=19)
d = dist(x, method = "euclidean")
hc = hclust(d, method="ward.D2")
windows(); plot(hc) # display dendrogram
k=2; clusters=cutree(hc, k) # cut tree into k clusters rect.hclust(hc, k, border="red")
table(clusters, class) # Confusion matrix
k=2; kmc = kmeans(x, k); clusters=kmc$cluster
plot(x, col = kmc$cluster,pch=19)
points(kmc$centers, col = 1:k, pch = 8, cex=3)
points(kmc$centers, col = 4:k, pch = 19, cex=2)
clusters
table(clusters)
cat("Cluster Centers:\n"); kmc$centers
table(clusters, class) # Confusion matrix
# ----------- Hungarian Method
cm=table(clusters,class); print(cm); #  plot(x,pch=19,col=hd.clust)
cat(" Wrong error.rate =",1-sum(diag(cm))/sum(cm),"\n")
match.label=minWeightBipartiteMatching(clusters,class)
id=c(match.label); cm=cm[,id];  print(cm)
cat("Error Rate:",1-sum(diag(cm))/sum(cm),"\n")
fval = qf(p=0.05, df1=4, df2=59,lower.tail = F)
fval
m = matrix(c(24.557143-20.09062,16.616667-20.09062,
4.571429-6.1875,7.444444-6.1875,
132.457142-230.72188,307.15-230.72188),byrow=T,nrow=3)
m
solve(m,c(0,0,0))
m = matrix(c(24.557143-20.09062,16.616667-20.09062,
4.571429-6.1875,7.444444-6.1875),byrow=T,nrow=2)
solve(m,c(0,0))
m = matrix(c(24.557143-20.09062,16.616667-20.09062,
0.06666694004,1.93333306),byrow=T,nrow=2)
solve(m,c(0,2.1334))
m = matrix(c(24.557143-20.09062,16.616667-20.09062,
1,1),byrow=T,nrow=2)
solve(m,c(0,32))
?pf
qf(p=0.05, df1=3, df2=28,lower.tail = F)
knitr::opts_chunk$set(echo = TRUE)
e2d = function(loc, cov, dis) {
A = solve(cov)
eA = eigen(A)
ev = eA$values
lambda1 = max(ev)
lambda2 = min(ev)
eigvect = eA$vectors[, order(ev)[2]]
z = seq(0, 2 * pi, by = 0.01)
z1 = dis/sqrt(lambda1) * cos(z)
z2 = dis/sqrt(lambda2) * sin(z)
alfa = atan(eigvect[2]/eigvect[1])
r <- matrix(c(cos(alfa), -sin(alfa), sin(alfa), cos(alfa)), ncol = 2)
z = t(t(cbind(z1, z2) %*% r) + loc)
}
# If type = 1: Concentration ellipse with dis = 1 - alpha
# Otherwise, an ellipse with distance = dis
ellipse=function(x,center,cov,dis,type=1){
if(class(x)== "data.frame") x=as.matrix(x)
if(class(x)!="matrix") stop("Data is not a matrix.")
if(ncol(x)!=2) stop("Number of variables should be 2.")
if(type==1) dis = sqrt(qchisq(dis, 2))
y=e2d(center,cov,dis); z=rbind(x,y)
plot(x, pch=19,cex=1.0,xlim=c(min(z[,1]),max(z[,1])),ylim=c(min(z[,2]),max(z[,2])) )
lines(y,col=4)
}
ellipse(c(0,0),c(0,1),matrix(c(9,0,0,4),nrow=2,byrow = T),1,type=1)
ellipse(c(0,0),c(0,1),matrix(c(9,0,0,4),nrow=2,byrow = T),1,type=2)
m=matrix(c(9,0,0,4),nrow=2,byrow = T)
m
ellipse(c(0,0),c(0,1),m,1,type=2)
ellipse(matrix(c(0,0)),c(0,1),m,1,type=2)
ellipse(data.frame(c(0,0)),c(0,1),m,1,type=2)
ellipse(data.frame(c(0,0)),c(0,1),m,1,type=1)
library(MASS)
mu = c(2,4)
sigma = matrix(c(2,2,2,4),nrow=2,ncol=2)
x1_bar = c()
x2_bar = c()
for (i in 1:10000){
bvn1 <- mvrnorm(50, mu = mu, Sigma = sigma )
x1_bar = c(x1_bar,colMeans(bvn1)[1])
x2_bar = c(x2_bar,colMeans(bvn1)[2])
}
cat("Correlation matrix of X1 and X2:\n\n")
cov2cor(sigma)
cat("\nCorrelation of X1 bar and X2 bar:\n")
cor(x1_bar,x2_bar)
data(longley)
longley = longley[,c(2,3,7)]
S = cov(longley)
S
subset_df = longley[,c(1,3)]
d = sqrt(max(edist(as.matrix(subset_df))))
edist = function(x){
ev = eigen(var(x))
d = diag(1/sqrt(ev$values))
b = ev$vectors%*%d%*%t(ev$vectors)
z = x%*%b
d = dist(z);  return(d) }
subset_df = longley[,c(1,3)]
d = sqrt(max(edist(as.matrix(subset_df))))
S = cov(subset_df)
S_eigen = eigen(S)
ellipse(subset_df,colMeans(subset_df),S,d,type=2)
ellipse(as.data.frame(x=(0,0)),colMeans(subset_df),S,d,type=2)
x = data.frame(0,0)
x
ellipse(x,colMeans(subset_df),S,d,type=2)
x = data.frame(0,1)
ellipse(x,colMeans(subset_df),S,d,type=2)
ellipse(x,c(0,1),m,1,type=2)
m
ellipse(x,c(0,1),m,1,type=2)
fval = qf(p=0.05, df1=4, df2=59,lower.tail = F)
fval
pval=pf(q=2.9, df1=4, df2=59,lower.tail = F)
pval
?qchisq
qchisq(0.05/337,df=6)
qchisq(0.05/337,df=6,lower.tal=F)
qchisq(0.05/337,df=6,lower.tail=F)
library(robustX)
setwd("~/Documents/Spring 2022/Multivariate/Project + Statistics + Distances + Hotellings")
df = read.csv('Life Expectancy Data.csv')
head(df)
df[,-c(1,2,3,4)]
df = df[,-c(1,2,3,4,5,6,7)]
head(df)
df = df[,-c(1,2,3)]
df
df = df[,-c(1,2,3)]
head(df)
mvBACON(df)
x = as.matrix(df)
mvBACON(x)
knitr::opts_chunk$set(echo = TRUE)
df = read.csv("Life Expectancy Data.csv")
df_2014 = df[df[,2]==2014,] # taking only observations from 2014
df_2014 = df_2014[ , colSums(is.na(df_2014)) == 0] # removing columns with NA
df_2014$Developing = model.matrix( ~ Status - 1, data=df_2014 )[,2] # creating binary variable
df_2014 = df_2014[,-c(2,3)]
colnames(df_2014) <- c("Country","LifeExp","AdultMort","InfDeaths","PercExp","Measles","UnderFive","Polio","Diphtheria","HIV.AIDS","Developing")
x = as.matrix(df_2014[,2:10])
output = mvBACON(x)
output
output$center
output$limit
v = matrix(c(1/sqrt(2),-1/sqrt(2),1/sqrt(2),1/sqrt(2)),nrow=2,byrow=T)
v
eig = matrix(c(4,0,0,2),nrow=2,byrow=T)
eig
v%*%eig%*%t(v)
v%*%eig%*%solve(v)
eiginv = matrix(c(1/4,0,0,1/2),nrow=2,byrow=T)
v%*%eiginv%*%solve(v)
eiginv = matrix(c(2,0,0,sqrt(2)),nrow=2,byrow=T)
v%*%eiginv%*%solve(v)
